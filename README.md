# Explainable AI Fundamentals

This repository contains a comprehensive Jupyter notebook that provides a hands-on introduction to core Explainable AI (XAI) methods across multiple data types and model architectures. It is designed to help practitioners and learners understand how to interpret, visualize, and trust machine learning and deep learning models.

## What Youâ€™ll Find Inside

- **Case Studies:** Real-world examples where ML models failed and the importance of explainability  
- **Exploratory Data Analysis (EDA):** Applied to structured, unstructured, and image/text data  
- **Post-hoc Explanation Visualizations:**  
  - Partial Dependence Plots (PDP)  
  - CNN-specific methods like Layer-wise Relevance Propagation (LRP), Guided Backpropagation, and Grad-CAM  
  - Surrogate model explainers  
- **Advanced Interpretation Techniques:**  
  - Feature importance using sensitivity analysis  
  - Counterfactual examples for actionable insights  
- **Local Explanation Methods:**  
  - LIME for tabular, image, and text data  
  - Various SHAP methods for local and global interpretability  
- **Transformer Model Explainability:** SHAP-based interpretation for transformers  
- **Human-Centric Explanation:** Using TCAV (Testing with Concept Activation Vectors) for concept-level insights  
